# ğŸ§  Retrieval-Augmented Generation (RAG) Using PocketFlow  
**Zero LangChain â€¢ Explicit Orchestration â€¢ Gemini + FAISS**

---

## ğŸ“Œ Overview

This repository implements a **complete Retrieval-Augmented Generation (RAG) system** using a **custom PocketFlow orchestration engine**.  
The system loads a PDF, builds a vector index, retrieves relevant context, and generates grounded answers using **Google Gemini** â€” **without LangChain or hidden abstractions**.

Everything is explicit, debuggable, and framework-free.

---

## ğŸš€ What This Project Does

- Loads a PDF document
- Extracts raw text from pages
- Splits text into overlapping chunks
- Generates vector embeddings
- Stores embeddings in **FAISS**
- Accepts user questions via terminal
- Retrieves relevant document chunks
- Builds a grounded prompt
- Generates answers using **Gemini**
- Loops until the user exits

---

## ğŸ› ï¸ Tech Stack

### Core Libraries
- **Python**
- **FAISS (faiss-cpu)** â€” vector similarity search
- **pypdf** â€” PDF text extraction
- **sentence-transformers** â€” embedding generation
- **google-generativeai** â€” Gemini LLM access

### Architecture
- **PocketFlow (custom implementation)** â€” workflow orchestration
- **No LangChain**
- **No implicit pipelines**
- **Explicit data flow**

---

## ğŸ§  Why PocketFlow?

PocketFlow is used instead of LangChain to achieve:

- Full control over execution
- Explicit step-by-step logic
- Conditional routing
- Easy debugging
- Interview- and production-friendly architecture

This project demonstrates **how RAG works internally**, not just how to call a framework.

---

## ğŸ§© High-Level Architecture

User Input
â†“
FAISS Retriever
â†“
Prompt Builder
â†“
Gemini LLM
â†“
Answer Display
â†“
Repeat


Input
  â†’ Retrieve
      â†’ Prompt
          â†’ Gemini
              â†’ Display
                  â†’ Input

---

## ğŸ” API Key Setup (Google Colab)

- Open **Colab â†’ Settings â†’ Secrets**
- Add the following secret:


- The API key is loaded securely at runtime  
- No API keys are hard-coded in the source code

---

## ğŸ“„ PDF Processing

### PDF Loading

- Uses **pypdf** to extract text from each page
- Combines all extracted text into a single string

### Text Chunking

- Chunk size: **200 characters**
- Overlap: **50 characters**
- Preserves semantic continuity across chunks

---

## ğŸ§¬ Embeddings & Vector Storage

### Embeddings

- Model: **all-MiniLM-L6-v2**
- Converts text chunks into dense numerical vectors

### FAISS Vector Store

- Index type: **IndexFlatL2**
- Enables fast semantic similarity search
- Stores all embeddings in memory

---

## ğŸ” Retrieval Logic

- User question is converted into an embedding
- FAISS performs similarity search
- Top-K relevant chunks are returned
- Retrieved chunks are used as context

This represents the **retrieval** stage of RAG.

---

## ğŸ¤– Gemini Generation

- Model: **Gemini 2.5 Flash**

### Input
- Retrieved context
- User question

### Prompt Rules
- Use **only** the provided context
- Do **not** hallucinate

### Output
- Grounded, document-based answer

---

## ğŸ§© PocketFlow Engine

### Core Concepts

- **Node** â€” one unit of work
- **Flow** â€” orchestrates node execution
- **Actions** â€” control transitions between nodes
- **Shared State** â€” passes data across nodes

This replaces LangChainâ€™s implicit chains with **explicit orchestration logic**.

---

## ğŸ§± PocketFlow Nodes Used

### InputNode
- Accepts user questions
- Detects exit command
- Stores current question

### RetrieveNode
- Queries FAISS
- Retrieves relevant document chunks
- Stores `{question, context}`

### PromptNode
- Builds the RAG prompt
- Enforces context-only answers

### GeminiNode
- Calls the Gemini API
- Handles empty or blocked responses
- Stores the generated answer

### DisplayNode
- Prints the final answer
- Clears shared state
- Loops back to input

---

## ğŸ”— Flow Wiring

Input
â†’ Retrieve
â†’ Prompt
â†’ Gemini
â†’ Display
â†’ Input


### Conditional Transitions Enable

- Continuous interaction
- Clean exit handling
- Safe execution paths

---

## â–¶ï¸ How to Run

1. Upload a PDF to Google Drive
2. Update the PDF path in the code
3. Add the Gemini API key to Colab Secrets
4. Run all notebook cells
5. Ask questions in the terminal
6. Type `exit` to stop

---

## âœ… What This Project Demonstrates

- RAG without frameworks
- Direct FAISS usage
- Manual prompt engineering
- Gemini LLM integration
- Explicit agent-style orchestration
- Production-grade reasoning flow

---

## ğŸ§  Interview Explanation

> *â€œI built a Retrieval-Augmented Generation system using a custom PocketFlow engine.  
> I manually implemented PDF parsing, chunking, embedding generation, FAISS indexing, retrieval, prompt construction, and Gemini-based generation â€” without using LangChain abstractions.â€*

---

## ğŸ”® Possible Extensions

- Async PocketFlow RAG
- Conversation memory
- Multi-document retrieval
- Tool-augmented RAG
- Streamlit or web UI
- Query routing agents
- RAG evaluation metrics

---

## ğŸ“Œ Final Note

This repository focuses on **understanding over shortcuts**.  
If you understand this code, you understand RAG.

