{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### üì¶ Install Required Dependencies\n",
        "\n",
        "This cell installs all low-level libraries needed to build a **pure RAG system without LangChain**.\n",
        "\n",
        "Libraries used:\n",
        "- `faiss-cpu` ‚Üí vector similarity search\n",
        "- `pypdf` ‚Üí extract raw text from PDFs\n",
        "- `sentence-transformers` ‚Üí generate embeddings\n",
        "- `google-generativeai` ‚Üí interact with Gemini models\n",
        "\n",
        "These are core building blocks. No framework abstractions.\n"
      ],
      "metadata": {
        "id": "wxmkbDY0UzZl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UM6KWNw5zHGr",
        "outputId": "fcade66d-12a3-4ac0-9e2c-3bb3dcb02b52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.6.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.28.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.43.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.12.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu pypdf sentence-transformers google-generativeai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîê Configure Google Gemini API\n",
        "\n",
        "This cell:\n",
        "1. Fetches the Gemini API key securely from **Colab Secrets**\n",
        "2. Sets it as an environment variable\n",
        "3. Configures the Google Generative AI client\n",
        "\n",
        "This avoids hard-coding sensitive keys and keeps the notebook safe for GitHub.\n"
      ],
      "metadata": {
        "id": "kK-BhRwBU0f7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"RAGAGENTKEY\")\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n"
      ],
      "metadata": {
        "id": "hFT7LzqN2mna"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß† PocketFlow Core Engine\n",
        "\n",
        "This cell defines a **minimal workflow engine** inspired by PocketFlow.\n",
        "\n",
        "Key concepts:\n",
        "- **Node** ‚Üí one unit of work\n",
        "- **Flow** ‚Üí orchestrates node execution\n",
        "- **Actions** ‚Üí determine next node (conditional routing)\n",
        "- **Shared state** ‚Üí used to pass data between nodes\n",
        "\n",
        "This replaces LangChain‚Äôs hidden pipelines with **explicit, debuggable execution logic**.\n"
      ],
      "metadata": {
        "id": "LgNQpbnZU12U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio, warnings, copy, time\n",
        "\n",
        "class BaseNode:\n",
        "    def __init__(self): self.params,self.successors={},{}\n",
        "    def set_params(self,params): self.params=params\n",
        "    def next(self,node,action=\"default\"):\n",
        "        if action in self.successors: warnings.warn(f\"Overwriting successor for action '{action}'\")\n",
        "        self.successors[action]=node; return node\n",
        "    def prep(self,shared): pass\n",
        "    def exec(self,prep_res): pass\n",
        "    def post(self,shared,prep_res,exec_res): pass\n",
        "    def _exec(self,prep_res): return self.exec(prep_res)\n",
        "    def _run(self,shared): p=self.prep(shared); e=self._exec(p); self.post(shared,p,e); return e # Modified line: return e\n",
        "    def run(self,shared):\n",
        "        if self.successors: warnings.warn(\"Node won't run successors. Use Flow.\")\n",
        "        return self._run(shared)\n",
        "    def __rshift__(self,other): return self.next(other)\n",
        "    def __sub__(self,action):\n",
        "        if isinstance(action,str): return _ConditionalTransition(self,action)\n",
        "        raise TypeError(\"Action must be a string\")\n",
        "\n",
        "class _ConditionalTransition:\n",
        "    def __init__(self,src,action): self.src,self.action=src,action\n",
        "    def __rshift__(self,tgt): return self.src.next(tgt,self.action)\n",
        "\n",
        "class Node(BaseNode):\n",
        "    def __init__(self,max_retries=1,wait=0): super().__init__(); self.max_retries,self.wait=max_retries,wait\n",
        "    def exec_fallback(self,prep_res,exc): raise exc\n",
        "    def _exec(self,prep_res):\n",
        "        for self.cur_retry in range(self.max_retries):\n",
        "            try: return self.exec(prep_res)\n",
        "            except Exception as e:\n",
        "                if self.cur_retry==self.max_retries-1: return self.exec_fallback(prep_res,e)\n",
        "                if self.wait>0: time.sleep(self.wait)\n",
        "\n",
        "class BatchNode(Node):\n",
        "    def _exec(self,items): return [super(BatchNode,self)._exec(i) for i in (items or [])]\n",
        "\n",
        "class Flow(BaseNode):\n",
        "    def __init__(self,start=None): super().__init__(); self.start_node=start\n",
        "    def start(self,start): self.start_node=start; return start\n",
        "    def get_next_node(self,curr,action):\n",
        "        nxt=curr.successors.get(action or \"default\")\n",
        "        if not nxt and curr.successors: warnings.warn(f\"Flow ends: '{action}' not found in {list(curr.successors)}\")\n",
        "        return nxt\n",
        "    def _orch(self,shared,params=None):\n",
        "        curr,p,last_action =copy.copy(self.start_node),(params or {**self.params}),None\n",
        "        while curr: curr.set_params(p); last_action=curr._run(shared); curr=copy.copy(self.get_next_node(curr,last_action))\n",
        "        return last_action\n",
        "    def _run(self,shared): p=self.prep(shared); o=self._orch(shared); return self.post(shared,p,o)\n",
        "    def post(self,shared,prep_res,exec_res): return exec_res\n",
        "\n",
        "class BatchFlow(Flow):\n",
        "    def _run(self,shared):\n",
        "        pr=self.prep(shared) or []\n",
        "        for bp in pr: self._orch(shared,{**self.params,**bp})\n",
        "        return self.post(shared,pr,None)\n",
        "\n",
        "class AsyncNode(Node):\n",
        "    async def prep_async(self,shared): pass\n",
        "    async def exec_async(self,prep_res): pass\n",
        "    async def exec_fallback_async(self,prep_res,exc): raise exc\n",
        "    async def post_async(self,shared,prep_res,exec_res): pass\n",
        "    async def _exec(self,prep_res):\n",
        "        for self.cur_retry in range(self.max_retries):\n",
        "            try: return await self.exec_async(prep_res)\n",
        "            except Exception as e:\n",
        "                if self.cur_retry==self.cur_retry-1: return await self.exec_fallback_async(prep_res,e)\n",
        "                if self.wait>0: await asyncio.sleep(self.wait)\n",
        "    async def run_async(self,shared):\n",
        "        if self.successors: warnings.warn(\"Node won't run successors. Use AsyncFlow.\")\n",
        "        return await self._run_async(shared)\n",
        "    async def _run_async(self,shared): p=await self.prep_async(shared); e=await self._exec(p); return await self.post_async(shared,p,e)\n",
        "    def _run(self,shared): raise RuntimeError(\"Use run_async.\")\n",
        "\n",
        "class AsyncBatchNode(AsyncNode,BatchNode):\n",
        "    async def _exec(self,items): return [await super(AsyncBatchNode,self)._exec(i) for i in items]\n",
        "\n",
        "class AsyncParallelBatchNode(AsyncNode,BatchNode):\n",
        "    async def _exec(self,items): return await asyncio.gather(*(super(AsyncParallelBatchNode,self)._exec(i) for i in items))\n",
        "\n",
        "class AsyncFlow(Flow,AsyncNode):\n",
        "    async def _orch_async(self,shared,params=None):\n",
        "        curr,p,last_action =copy.copy(self.start_node),(params or {**self.params}),None\n",
        "        while curr: curr.set_params(p); last_action=await curr._run_async(shared) if isinstance(curr,AsyncNode) else curr._run(shared); curr=copy.copy(self.get_next_node(curr,last_action))\n",
        "        return last_action\n",
        "    async def _run_async(self,shared): p=await self.prep_async(shared); o=await self._orch_async(shared); return await self.post_async(shared,p,o)\n",
        "    async def post_async(self,shared,prep_res,exec_res): return exec_res\n",
        "\n",
        "class AsyncBatchFlow(AsyncFlow,BatchFlow):\n",
        "    async def _run_async(self,shared):\n",
        "        pr=await self.prep_async(shared) or []\n",
        "        for bp in pr: await self._orch_async(shared,{**self.params,**bp})\n",
        "        return await self.post_async(shared,pr,None)\n",
        "\n",
        "class AsyncParallelBatchFlow(AsyncFlow,BatchFlow):\n",
        "    async def _run_async(self,shared):\n",
        "        pr=await self.prep_async(shared) or []\n",
        "        await asyncio.gather(*(self._orch_async(shared,{**self.params,**bp}) for bp in pr))\n",
        "        return await self.post_async(shared,pr,None)"
      ],
      "metadata": {
        "id": "UoWAb4cPOkx4"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üìÑ Load PDF File\n",
        "\n",
        "This cell:\n",
        "- Uses `pypdf` to read a PDF file\n",
        "- Extracts raw text from every page\n",
        "- Combines all page text into a single string\n",
        "\n",
        "This is the first step of the RAG pipeline: **getting raw knowledge**.\n"
      ],
      "metadata": {
        "id": "3O2TtYbWU380"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader\n",
        "\n",
        "def load_pdf(path):\n",
        "    reader = PdfReader(path)\n",
        "    text = \"\"\n",
        "    for page in reader.pages:\n",
        "        text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "raw_text = load_pdf(\"/content/drive/MyDrive/PDF/RAG.pdf\")\n"
      ],
      "metadata": {
        "id": "G_iniRrQ2mkw"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚úÇÔ∏è Split Text into Chunks\n",
        "\n",
        "Large text cannot be embedded directly.\n",
        "\n",
        "This function:\n",
        "- Breaks text into chunks of 200 characters\n",
        "- Uses 50-character overlap to preserve context\n",
        "- Produces a list of small, searchable text chunks\n",
        "\n",
        "This replaces LangChain text splitters with a transparent approach.\n"
      ],
      "metadata": {
        "id": "0X-Aef5eU5YR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_text(text, chunk_size=200, overlap=50):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = start + chunk_size\n",
        "        chunks.append(text[start:end])\n",
        "        start = end - overlap\n",
        "    return chunks\n",
        "\n",
        "chunks = split_text(raw_text)\n"
      ],
      "metadata": {
        "id": "hI1BghIU2mh_"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üß¨ Generate Embeddings\n",
        "\n",
        "This cell:\n",
        "- Loads a lightweight embedding model (`all-MiniLM-L6-v2`)\n",
        "- Converts each text chunk into a numerical vector\n",
        "\n",
        "Embeddings allow semantic similarity search instead of keyword matching.\n"
      ],
      "metadata": {
        "id": "ibrxLMmXU7N3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings = embed_model.encode(chunks)\n"
      ],
      "metadata": {
        "id": "LW7zfIqH3H_v"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üóÇÔ∏è Store Embeddings in FAISS\n",
        "\n",
        "This cell:\n",
        "- Creates a FAISS index based on embedding dimensions\n",
        "- Stores all embeddings for fast similarity search\n",
        "\n",
        "FAISS is used directly ‚Äî no LangChain wrappers.\n"
      ],
      "metadata": {
        "id": "NMxnA4aeU-kq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(np.array(embeddings))\n"
      ],
      "metadata": {
        "id": "gJjgtJXp2mfa"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîç Semantic Retriever\n",
        "\n",
        "This function:\n",
        "1. Converts the user query into an embedding\n",
        "2. Searches FAISS for the most similar chunks\n",
        "3. Returns the top-K relevant text chunks\n",
        "\n",
        "This is the **retrieval** part of RAG.\n"
      ],
      "metadata": {
        "id": "7EwtpfAwU_ep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(query, top_k=5):\n",
        "    q_embedding = embed_model.encode([query])\n",
        "    distances, indices = index.search(np.array(q_embedding), top_k)\n",
        "    return [chunks[i] for i in indices[0]]\n"
      ],
      "metadata": {
        "id": "a8LXS2yb2mcm"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ü§ñ Initialize Gemini Model\n",
        "\n",
        "This cell:\n",
        "- Loads the Gemini Flash model\n",
        "- Prepares it for text generation\n",
        "\n",
        "Gemini is used only for **generation**, not retrieval.\n",
        "### üì§ Gemini Call Wrapper\n",
        "\n",
        "This helper function:\n",
        "- Sends a prompt to Gemini\n",
        "- Returns only the generated text\n",
        "\n",
        "All Gemini interaction is centralized here.\n"
      ],
      "metadata": {
        "id": "JIYs13aaVBEb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "\n",
        "def call_gemini(prompt):\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n"
      ],
      "metadata": {
        "id": "72Cn0j_b2mZ6"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚å®Ô∏è Input Node\n",
        "\n",
        "This node:\n",
        "- Accepts user questions from the terminal\n",
        "- Detects `exit` to stop the flow\n",
        "- Stores the current question in shared state\n",
        "- Emits an action to control flow routing\n",
        "\n",
        "This is the entry point for each RAG query.\n"
      ],
      "metadata": {
        "id": "YF5jdnV3VCdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InputNode(Node):\n",
        "    def exec(self, _):\n",
        "        q = input(\"Ask a question (or exit): \").strip()\n",
        "        if q.lower() == \"exit\":\n",
        "            return \"exit_flow\"\n",
        "        self.question_input = q # Temporarily store to pass via post\n",
        "        return \"question_available\" # Action for flow to proceed\n",
        "\n",
        "    def post(self, shared, prep_res, exec_res):\n",
        "        if exec_res == \"question_available\":\n",
        "            shared['current_question'] = self.question_input\n",
        "        elif 'current_question' in shared: # If exiting, clear question\n",
        "            del shared['current_question']\n",
        "        return exec_res # This return becomes `last_action` in Flow"
      ],
      "metadata": {
        "id": "5g9BNYer2mXY"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîé Retrieve Node\n",
        "\n",
        "This node:\n",
        "- Reads the current question\n",
        "- Retrieves relevant chunks from FAISS\n",
        "- Stores `{question, context}` in shared state\n",
        "\n",
        "This connects user input to document knowledge.\n"
      ],
      "metadata": {
        "id": "njiI-XBDVOh6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RetrieveNode(Node):\n",
        "    def prep(self, shared):\n",
        "        return shared.get('current_question') # Get question from shared state\n",
        "\n",
        "    def exec(self, question):\n",
        "        if question is None:\n",
        "            return \"exit_flow\"\n",
        "        context = retrieve(question)\n",
        "        self.retrieved_data = {\"question\": question, \"context\": context}\n",
        "        return \"context_available\"\n",
        "\n",
        "    def post(self, shared, prep_res, exec_res):\n",
        "        if exec_res == \"context_available\":\n",
        "            shared['retrieved_data'] = self.retrieved_data\n",
        "        elif 'retrieved_data' in shared:\n",
        "            del shared['retrieved_data']\n",
        "        return exec_res # Pass action to Flow"
      ],
      "metadata": {
        "id": "LwrZxFwM2u8u"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üßæ Prompt Builder Node\n",
        "\n",
        "This node:\n",
        "- Combines retrieved context + user question\n",
        "- Enforces ‚Äúanswer only from context‚Äù\n",
        "- Prevents hallucinations\n",
        "\n",
        "This is where **retrieval becomes generation**.\n"
      ],
      "metadata": {
        "id": "Jvv-k4kQVPua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PromptNode(Node):\n",
        "    def prep(self, shared):\n",
        "        return shared.get('retrieved_data')\n",
        "\n",
        "    def exec(self, data):\n",
        "        if data is None or data.get('question') is None:\n",
        "            return \"exit_flow\"\n",
        "\n",
        "        context_text = \"\\n\".join(data[\"context\"])\n",
        "        prompt = f\"\"\"\n",
        "You are a smart assistant.\n",
        "Answer ONLY using the context.\n",
        "Do not hallucinate.\n",
        "\n",
        "Context:\n",
        "{context_text}\n",
        "\n",
        "Question:\n",
        "{data['question']}\n",
        "\"\"\"\n",
        "        self.prepared_prompt = prompt\n",
        "        return \"prompt_ready\"\n",
        "\n",
        "    def post(self, shared, prep_res, exec_res):\n",
        "        if exec_res == \"prompt_ready\":\n",
        "            shared['generated_prompt'] = self.prepared_prompt\n",
        "        elif 'generated_prompt' in shared:\n",
        "            del shared['generated_prompt']\n",
        "        return exec_res"
      ],
      "metadata": {
        "id": "IHMu1ySA2u6m"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ü§ñ Gemini Generation Node\n",
        "\n",
        "This node:\n",
        "- Sends the prepared prompt to Gemini\n",
        "- Handles safety / empty responses\n",
        "- Stores the generated answer\n",
        "\n",
        "Errors are caught so the flow never crashes.\n"
      ],
      "metadata": {
        "id": "zfzKSFtkVRJh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GeminiNode(Node):\n",
        "    def prep(self, shared):\n",
        "        return shared.get('generated_prompt')\n",
        "\n",
        "    def exec(self, prompt):\n",
        "        if prompt is None:\n",
        "            return \"exit_flow\"\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            generated_text = \"\"\n",
        "            if response.candidates:\n",
        "                if hasattr(response.candidates[0].content, 'parts') and response.candidates[0].content.parts:\n",
        "                    generated_text = response.text\n",
        "                else:\n",
        "                    print(\"Warning: Gemini API generated no text content (possibly blocked by safety filters).\")\n",
        "                    generated_text = \"No answer generated due to content policy or other issues.\"\n",
        "            else:\n",
        "                print(\"Warning: Gemini API returned no candidates.\")\n",
        "                generated_text = \"No answer generated.\"\n",
        "\n",
        "            self.gemini_output = generated_text\n",
        "            return \"answer_ready\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error during Gemini API call: {e}\")\n",
        "            self.gemini_output = f\"Error: Could not generate answer: {e}\"\n",
        "            return \"answer_ready\"\n",
        "\n",
        "    def post(self, shared, prep_res, exec_res):\n",
        "        if exec_res == \"answer_ready\":\n",
        "            shared['generated_answer'] = self.gemini_output\n",
        "        elif 'generated_answer' in shared:\n",
        "            del shared['generated_answer']\n",
        "        return exec_res"
      ],
      "metadata": {
        "id": "LhugNB5I2u4I"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üñ•Ô∏è Display Node\n",
        "\n",
        "This node:\n",
        "- Prints the final answer to the user\n",
        "- Clears previous state to avoid data leakage\n",
        "- Loops control back to the input node\n",
        "\n",
        "This ensures each question is handled cleanly.\n"
      ],
      "metadata": {
        "id": "sLheZjhhVSga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DisplayNode(Node):\n",
        "    def prep(self, shared):\n",
        "        return shared.get('generated_answer')\n",
        "\n",
        "    def exec(self, answer):\n",
        "        if answer is None: # Propagate exit if no answer was generated upstream\n",
        "            return \"exit_flow\"\n",
        "        print(\"\\nAnswer:\\n\", answer, \"\\n\")\n",
        "        return \"continue_conversation\" # Loop back to input\n",
        "\n",
        "    def post(self, shared, prep_res, exec_res):\n",
        "        # Clear previous answers/prompts/contexts to avoid showing old data on next loop\n",
        "        if 'generated_answer' in shared:\n",
        "            del shared['generated_answer']\n",
        "        if 'generated_prompt' in shared:\n",
        "            del shared['generated_prompt']\n",
        "        if 'retrieved_data' in shared:\n",
        "            del shared['retrieved_data']\n",
        "        if 'current_question' in shared:\n",
        "            del shared['current_question']\n",
        "        return exec_res"
      ],
      "metadata": {
        "id": "eAO0Lcot2xVY"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üîó Flow Wiring (RAG Graph)\n",
        "\n",
        "This cell defines the execution graph:\n",
        "\n",
        "Input ‚Üí Retrieve ‚Üí Prompt ‚Üí Gemini ‚Üí Display ‚Üí Input\n",
        "\n",
        "Conditional transitions allow:\n",
        "- Looping\n",
        "- Clean exits\n",
        "- Controlled execution paths\n",
        "\n",
        "This is **explicit agent orchestration**, not magic chaining.\n"
      ],
      "metadata": {
        "id": "A0gotkQxVT_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_node = InputNode()\n",
        "retrieve_node = RetrieveNode()\n",
        "prompt_node = PromptNode()\n",
        "gemini_node = GeminiNode()\n",
        "display_node = DisplayNode()\n",
        "\n",
        "flow = Flow(input_node)\n",
        "\n",
        "input_node - \"question_available\" >> retrieve_node\n",
        "retrieve_node - \"context_available\" >> prompt_node\n",
        "prompt_node - \"prompt_ready\" >> gemini_node\n",
        "gemini_node - \"answer_ready\" >> display_node\n",
        "\n",
        "# Loop back for continuation\n",
        "display_node - \"continue_conversation\" >> input_node\n",
        "\n",
        "# Handle exit from any point in the flow\n",
        "input_node - \"exit_flow\" >> None\n",
        "retrieve_node - \"exit_flow\" >> None\n",
        "prompt_node - \"exit_flow\" >> None\n",
        "gemini_node - \"exit_flow\" >> None\n",
        "display_node - \"exit_flow\" >> None"
      ],
      "metadata": {
        "id": "wip7NVDo4YZR"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚ñ∂Ô∏è Run the PocketFlow RAG System\n",
        "\n",
        "This cell:\n",
        "- Instantiates the flow\n",
        "- Starts execution\n",
        "- Keeps the chatbot running until exit\n",
        "\n",
        "You now have a fully working **PocketFlow-driven RAG system**.\n"
      ],
      "metadata": {
        "id": "TLH2sIWrVVi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flow._run({})"
      ],
      "metadata": {
        "id": "HdlnIK384ZmV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "outputId": "8d1eca74-f7d7-4a94-e8b7-0f6fca23c831"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ask a question (or exit):  Ask a question (or exit): What is RAG-Sequence Model? /tmp/ipython-input-402709136.py:44: UserWarning: Flow ends: 'What is RAG-Sequence Model?' not found in ['default']   if not nxt and curr.successors: warnings.warn(f\"Flow ends: '{action}' not found in {list(curr.successors)}\") 'What is RAG-Sequence Model?'\n",
            "\n",
            "Answer:\n",
            " The RAG-Sequence model uses the same retrieved document to generate the complete sequence. \n",
            "\n",
            "Ask a question (or exit): what are  Training setup Details?\n",
            "\n",
            "Answer:\n",
            " The training setup details include:\n",
            "\n",
            "*   **Trainable Parameters:** A total of 626M trainable parameters, including T-large with 406M parameters.\n",
            "*   **Knowledge Access:** The ability to access knowledge is present without additional training, achieved by using pre-trained access mechanisms.\n",
            "*   **Training Type:** \"Mixed precision training\" is referenced from ICLR 2018 papers.\n",
            "*   **Datasets and Instances (Train, Development, Test):**\n",
            "    *   **Natural Questions:** 79169, 8758, 3611\n",
            "    *   **TriviaQA:** 78786, 8838, 11314\n",
            "    *   **WebQuestions:** 3418, 362, 2033\n",
            "    *   **CuratedTrec:** 635, 134, 635\n",
            "    *   **Jeopardy Question Generation:** 97392, 13714, 2684\n",
            "    *   *A hidden subset of this data is used for evaluation.* \n",
            "\n",
            "Ask a question (or exit): Appendices for Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks\n",
            "\n",
            "Answer:\n",
            " A Implementation Details \n",
            "\n",
            "Ask a question (or exit): what are Implementation Details\n",
            "\n",
            "Answer:\n",
            " I am sorry, but the context provided does not contain information about \"Implementation Details\". \n",
            "\n",
            "Ask a question (or exit): tell me any 3 References\n",
            "\n",
            "Answer:\n",
            " 1.  [61] Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel Bowman. Super 3/v1/W18-5713. URL https://www.aclweb.org/anthology/W18-5713.\n",
            "2.  [66] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R√©mi Louf, Mos. doi: 10.18653/v1/D19-1244. URL https://www.aclweb.org/anthology/D19-1244.\n",
            "3.  [47] Fabio Petroni, Tim Rockt√§schel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, and Alexander Miller. Lang Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, Mir Rosenberg, Xia Song, Alina Stoica, Saurabh Tiwary, and Tong Wang. MS MARCO: A Human Gen 423. URL https://www.aclweb.org/anthology/N19-1423. \n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-744300896.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-402709136.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, shared)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mcurr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcurr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mlast_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mcurr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlast_action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprep_res\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexec_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mexec_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-402709136.py\u001b[0m in \u001b[0;36m_orch\u001b[0;34m(self, shared, params)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_orch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mcurr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_action\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0mcurr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcurr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mlast_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mcurr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlast_action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-402709136.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, shared)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprep_res\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexec_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprep_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0me\u001b[0m \u001b[0;31m# Modified line: return e\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshared\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccessors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Node won't run successors. Use Flow.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-402709136.py\u001b[0m in \u001b[0;36m_exec\u001b[0;34m(self, prep_res)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_exec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprep_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_retry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_retry\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_res\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2270479814.py\u001b[0m in \u001b[0;36mexec\u001b[0;34m(self, _)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mInputNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ask a question (or exit): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"exit_flow\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}